{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_egg_NLP_Task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFWRSE4A/jCjMrfJMv849J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbfd8561ec8d44f5b437fe8f8e74987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24f6e9ba659849e5a0d6c761fcf43d7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2c3405b3f1e4fe19b3aba8d730e6784",
              "IPY_MODEL_f9ba445e85ba47d3ad005f5bd3d12b61",
              "IPY_MODEL_f5c6f9a6b52e4eb8bed0911d790f1c49"
            ]
          }
        },
        "24f6e9ba659849e5a0d6c761fcf43d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2c3405b3f1e4fe19b3aba8d730e6784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e12a9ca07ea94837884c77362d26c8b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe79b09fe0fd41ae9a32d28ead365106"
          }
        },
        "f9ba445e85ba47d3ad005f5bd3d12b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8b0a115a1824fceb4645029d3e0b6b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ea30eb98bf14eaaa37bf1d9160d2e19"
          }
        },
        "f5c6f9a6b52e4eb8bed0911d790f1c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4f4e5308b1442c7bf094861d9c14b19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 25.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b5dfc17b10f453493ff74f05703235d"
          }
        },
        "e12a9ca07ea94837884c77362d26c8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe79b09fe0fd41ae9a32d28ead365106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8b0a115a1824fceb4645029d3e0b6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ea30eb98bf14eaaa37bf1d9160d2e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4f4e5308b1442c7bf094861d9c14b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b5dfc17b10f453493ff74f05703235d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69988315cf2646cf8a82ce0345489334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c618fb75aa364bca809305a02eb60c87",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2695dfe4037f47e09d2587c32fbc1a3e",
              "IPY_MODEL_f099033504b6469e999451ce329daf5b",
              "IPY_MODEL_6fa3b88fa731413e9937fcc5c5b8b5ec"
            ]
          }
        },
        "c618fb75aa364bca809305a02eb60c87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2695dfe4037f47e09d2587c32fbc1a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a695ee6f1c2c4a569b4726c41bca0973",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37d5f2745eb046858c14d416711dffc6"
          }
        },
        "f099033504b6469e999451ce329daf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea854710df8d4b1593a49f1d38c6f8cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8d1e558011d426082f13d6c5bac3d2c"
          }
        },
        "6fa3b88fa731413e9937fcc5c5b8b5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8093e307fa374c998c0e453f56152675",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:08&lt;00:00, 34.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75149f246e394d13ba57b4b08a5cbd9b"
          }
        },
        "a695ee6f1c2c4a569b4726c41bca0973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37d5f2745eb046858c14d416711dffc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea854710df8d4b1593a49f1d38c6f8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8d1e558011d426082f13d6c5bac3d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8093e307fa374c998c0e453f56152675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75149f246e394d13ba57b4b08a5cbd9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73487af582de4c82b25f663b797536e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb4a03652bb24e40b72bdd84567c52c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32a3b9b3a78f4178b893eced10e9cf0a",
              "IPY_MODEL_c0a1c57635da4ca4ad0be9300a883387",
              "IPY_MODEL_c2fe4bd46733475899c7c4f11c147c20"
            ]
          }
        },
        "fb4a03652bb24e40b72bdd84567c52c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32a3b9b3a78f4178b893eced10e9cf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_873afcc1c3df40be85c62fb729875e12",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b457dce4ea8b4fb993bd1ba8b196724f"
          }
        },
        "c0a1c57635da4ca4ad0be9300a883387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e16d6777fc24382b396105adacd6285",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_419d2a7830eb49858d85428d969cd9b5"
          }
        },
        "c2fe4bd46733475899c7c4f11c147c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_149d084b407c46f1bc83ab5128d80293",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 365kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c36ee96fef34124bcf4b1342f7e8012"
          }
        },
        "873afcc1c3df40be85c62fb729875e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b457dce4ea8b4fb993bd1ba8b196724f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e16d6777fc24382b396105adacd6285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "419d2a7830eb49858d85428d969cd9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "149d084b407c46f1bc83ab5128d80293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c36ee96fef34124bcf4b1342f7e8012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff0a9b0d646848e0b2cbcf7c66637f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b82e196d8bcf4c9d832f593ef9af94f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2fcf701333b442caa1f776bd8cf1b574",
              "IPY_MODEL_ca55751df4144b86aad2f6d6e9b381f4",
              "IPY_MODEL_69b90d3413c5409cb4e726a33709c67e"
            ]
          }
        },
        "b82e196d8bcf4c9d832f593ef9af94f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fcf701333b442caa1f776bd8cf1b574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7073104b3a114e478dfb705ad1a5b0f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7685443c7784c73b22cf15a39ccaa29"
          }
        },
        "ca55751df4144b86aad2f6d6e9b381f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fdf76ad6b4334ed19d921be10e47aea5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5edcc44c556f43e782fad859e1cf5cb9"
          }
        },
        "69b90d3413c5409cb4e726a33709c67e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbe19988bc1044df9d1670a58d554f0e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 633kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5f2b7d41cb2418fbff8a7b60ecc3ef9"
          }
        },
        "7073104b3a114e478dfb705ad1a5b0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7685443c7784c73b22cf15a39ccaa29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdf76ad6b4334ed19d921be10e47aea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5edcc44c556f43e782fad859e1cf5cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbe19988bc1044df9d1670a58d554f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5f2b7d41cb2418fbff8a7b60ecc3ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceda2ef6b4a44d3c8af19d3fe908a24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c949640e25574d1faceddb7eb8954673",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3af39f5b4fff4e7f8f13f22b3cd80dcd",
              "IPY_MODEL_63b9673ef82849b1b6478a72aa29bada",
              "IPY_MODEL_9d1ee288c4214d809ef3ee6b93deca17"
            ]
          }
        },
        "c949640e25574d1faceddb7eb8954673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3af39f5b4fff4e7f8f13f22b3cd80dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a812f639f9c249a79b7661783c3b350b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_894ccd8552c342dea79de650d464990c"
          }
        },
        "63b9673ef82849b1b6478a72aa29bada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7dffe1376f6244f28ab1d9534d0dbc24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52eb62637853483d864d1228c96b4789"
          }
        },
        "9d1ee288c4214d809ef3ee6b93deca17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82754abaab134ea6846ae1b21e8bdbe1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.22kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70592360f9264e9996d66c20e7cdb231"
          }
        },
        "a812f639f9c249a79b7661783c3b350b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "894ccd8552c342dea79de650d464990c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dffe1376f6244f28ab1d9534d0dbc24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52eb62637853483d864d1228c96b4789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82754abaab134ea6846ae1b21e8bdbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70592360f9264e9996d66c20e7cdb231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnesGokceDS/Score_Prediction/blob/main/Best_egg_NLP_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MarletteFunding/marlette-ds-challenge2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqu4STY8CmpF",
        "outputId": "3b3a199d-c72e-4d88-d42f-e8ecdd8dd8d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'marlette-ds-challenge2'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 3 (delta 0), pack-reused 4\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VmwotSQ_Ca1z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv('marlette-ds-challenge2/NLP_task_train.csv.zip',header=0,index_col=0,compression='infer')\n",
        "df_validate = pd.read_csv('marlette-ds-challenge2/NLP_task_validate.csv.zip',header=0,index_col=0,compression='infer')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Q_1RAilRCtdd",
        "outputId": "a06b57bd-fb0a-43e0-e289-2367e667597c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3dab0ac2-001b-42a5-a96e-efd5dfb8590e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOCUMENT_ID</th>\n",
              "      <th>SENTENCE_ID</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>SENTENCE_START_POS</th>\n",
              "      <th>SENTENCE_END_POS</th>\n",
              "      <th>SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>583306034</td>\n",
              "      <td>1888104</td>\n",
              "      <td>The whole process went smooth and I am thankfu...</td>\n",
              "      <td>109</td>\n",
              "      <td>165</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>583306034</td>\n",
              "      <td>1888102</td>\n",
              "      <td>It was quick and easy to apply and got the app...</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>584193040</td>\n",
              "      <td>1909902</td>\n",
              "      <td>service</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>584203035</td>\n",
              "      <td>1910310</td>\n",
              "      <td>Thanks!</td>\n",
              "      <td>198</td>\n",
              "      <td>205</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>584200037</td>\n",
              "      <td>1910006</td>\n",
              "      <td>Thank you!</td>\n",
              "      <td>58</td>\n",
              "      <td>68</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dab0ac2-001b-42a5-a96e-efd5dfb8590e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3dab0ac2-001b-42a5-a96e-efd5dfb8590e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3dab0ac2-001b-42a5-a96e-efd5dfb8590e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   DOCUMENT_ID  SENTENCE_ID  ... SENTENCE_END_POS  SCORE\n",
              "0    583306034      1888104  ...              165   10.0\n",
              "1    583306034      1888102  ...               60   10.0\n",
              "2    584193040      1909902  ...                7   10.0\n",
              "3    584203035      1910310  ...              205   10.0\n",
              "4    584200037      1910006  ...               68   10.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.SCORE.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiVFqFiVDsNl",
        "outputId": "3a80f3ee-4f0b-4ce6-ca9d-52e59ff19802"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.0    43843\n",
              "9.0      6214\n",
              "8.0      3632\n",
              "7.0      1297\n",
              "5.0       516\n",
              "6.0       434\n",
              "0.0       227\n",
              "4.0       192\n",
              "3.0       127\n",
              "1.0        83\n",
              "2.0        79\n",
              "Name: SCORE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO_AYHvoCwl9",
        "outputId": "5324bcdf-b62c-48e6-a626-b3bdc88bbe27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56644 entries, 0 to 70662\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   DOCUMENT_ID         56644 non-null  int64  \n",
            " 1   SENTENCE_ID         56644 non-null  int64  \n",
            " 2   SENTENCE            56623 non-null  object \n",
            " 3   SENTENCE_START_POS  56644 non-null  int64  \n",
            " 4   SENTENCE_END_POS    56644 non-null  int64  \n",
            " 5   SCORE               56644 non-null  float64\n",
            "dtypes: float64(1), int64(4), object(1)\n",
            "memory usage: 3.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_validate.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y0Bt0OP-Czhd",
        "outputId": "a1f09238-3250-4f81-9b6f-02076fe2af42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1f59e0b3-d3ee-4a39-81b8-0fcfb8921fdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DOCUMENT_ID</th>\n",
              "      <th>SENTENCE_ID</th>\n",
              "      <th>SENTENCE</th>\n",
              "      <th>SENTENCE_START_POS</th>\n",
              "      <th>SENTENCE_END_POS</th>\n",
              "      <th>SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>584207033</td>\n",
              "      <td>1910601</td>\n",
              "      <td>The loan process was super easy</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>584199033</td>\n",
              "      <td>1909801</td>\n",
              "      <td>The process was quick and easy!</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>591377035</td>\n",
              "      <td>2116637</td>\n",
              "      <td>were in my bank within just a few days from th...</td>\n",
              "      <td>178</td>\n",
              "      <td>252</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>591377035</td>\n",
              "      <td>2116635</td>\n",
              "      <td>I do not know what you mean by \"my score\", but...</td>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>34211545</td>\n",
              "      <td>359794</td>\n",
              "      <td>Very expensive dental work and debt consolidat...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f59e0b3-d3ee-4a39-81b8-0fcfb8921fdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f59e0b3-d3ee-4a39-81b8-0fcfb8921fdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f59e0b3-d3ee-4a39-81b8-0fcfb8921fdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    DOCUMENT_ID  SENTENCE_ID  ... SENTENCE_END_POS  SCORE\n",
              "7     584207033      1910601  ...               31   10.0\n",
              "10    584199033      1909801  ...               31    9.0\n",
              "13    591377035      2116637  ...              252   10.0\n",
              "14    591377035      2116635  ...              131   10.0\n",
              "25     34211545       359794  ...               50   10.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_validate.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suUMoRaKPsFD",
        "outputId": "c0de2617-fe3f-4d78-df96-e0c685101487"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 14019 entries, 7 to 70658\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   DOCUMENT_ID         14019 non-null  int64  \n",
            " 1   SENTENCE_ID         14019 non-null  int64  \n",
            " 2   SENTENCE            14015 non-null  object \n",
            " 3   SENTENCE_START_POS  14019 non-null  int64  \n",
            " 4   SENTENCE_END_POS    14019 non-null  int64  \n",
            " 5   SCORE               14018 non-null  float64\n",
            "dtypes: float64(1), int64(4), object(1)\n",
            "memory usage: 766.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning Processes**\n",
        "\n",
        "We will make some basic text cleaning that can be used with BERT. While using BERT, we should stay away from some text cleaning processes used in rules-based prediction models such as stemming, lemmatization, expanding contractions etc. "
      ],
      "metadata": {
        "id": "FxL-Ph94FXaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Make all text lower-case characters**\n",
        "\n",
        "Cased or uncased are both reasonable approach. But, according to BERT official Github guide, upper case characters doesn't bring performance improvment in text classification. All text can be lowered. In tasks like NER, upper-case characters can be important, and needs to kept."
      ],
      "metadata": {
        "id": "qio5Z3ugI9W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.SENTENCE = df_train.SENTENCE.astype('str') # sometimes sentences aren't read as str. This prevents such an error.\n",
        "df_train['clean_text'] = df_train.SENTENCE.str.lower()"
      ],
      "metadata": {
        "id": "P2nnxpvGDZft"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Remove punctuation\n",
        "\n",
        "According to some studies, BERT doesn't bring performance improvment by keeping punctuations. The reason behind this is that in many textual data, punctuation doesn't change the meaning drastically in a way to affect BERT text reading system. One day, if there are a dataset that punctuation has a critical impact on the meaning, punctuation can be kept. \n",
        "\n",
        "Removing punctuation will descrease token length. Keep in mind that BERT can read up to 512 token. Also, lesser token length will make compuation easier. That's why removing punctuation is a justifiable step.\n",
        "\n",
        "> Based on similar justification, we don't expand contractions. Google Research official Github page also states this point, and suggests not to expand contractions."
      ],
      "metadata": {
        "id": "hNb27wNbJQX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuations and multiple spaces\n",
        "import re\n",
        "df_train['clean_text'] = df_train['clean_text'].apply(lambda x: re.sub(r\"[,.;@#?!&$-+]+\\ *\", \" \", x))"
      ],
      "metadata": {
        "id": "dm7WPIZjFoh0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Check if there is any null sentence in train and validation datasets**"
      ],
      "metadata": {
        "id": "KDWR_dTNVP_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.SENTENCE.isnull().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGmeTR-iVV35",
        "outputId": "2774d87f-e184-43b9-c954-82e610faff50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    56644\n",
              "Name: SENTENCE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.SCORE.isnull().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9tcJmmcWHCh",
        "outputId": "09db2fee-0ca3-40e1-d6ed-110a0a7ecd26"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    56644\n",
              "Name: SCORE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_validate.SENTENCE.isnull().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_JLRPCgVUqZ",
        "outputId": "3cd193a0-b653-49b0-f45c-085aeb3b1575"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    14015\n",
              "True         4\n",
              "Name: SENTENCE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_validate.SCORE.isnull().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jqUCfZDWDs4",
        "outputId": "4e1f61f8-c54f-4ccb-9a31-bffb3c4e9cf8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    14018\n",
              "True         1\n",
              "Name: SCORE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can remove the null SENTENCES and SCORE from validation dataset\n",
        "df_validate = df_validate.dropna(subset=['SCORE', 'SENTENCE'])"
      ],
      "metadata": {
        "id": "FE6t-iPEVcFp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train The BERT MODEL**\n"
      ],
      "metadata": {
        "id": "zP6wer_JNdjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUX32WgYNjp7",
        "outputId": "fd07c367-c7be-4384-b5fb-4c8930c6fa11"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 22.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 22.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 641 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 85.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "1atsx2kZGr9B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "fbfd8561ec8d44f5b437fe8f8e74987a",
            "24f6e9ba659849e5a0d6c761fcf43d7f",
            "f2c3405b3f1e4fe19b3aba8d730e6784",
            "f9ba445e85ba47d3ad005f5bd3d12b61",
            "f5c6f9a6b52e4eb8bed0911d790f1c49",
            "e12a9ca07ea94837884c77362d26c8b1",
            "fe79b09fe0fd41ae9a32d28ead365106",
            "e8b0a115a1824fceb4645029d3e0b6b9",
            "6ea30eb98bf14eaaa37bf1d9160d2e19",
            "e4f4e5308b1442c7bf094861d9c14b19",
            "8b5dfc17b10f453493ff74f05703235d",
            "69988315cf2646cf8a82ce0345489334",
            "c618fb75aa364bca809305a02eb60c87",
            "2695dfe4037f47e09d2587c32fbc1a3e",
            "f099033504b6469e999451ce329daf5b",
            "6fa3b88fa731413e9937fcc5c5b8b5ec",
            "a695ee6f1c2c4a569b4726c41bca0973",
            "37d5f2745eb046858c14d416711dffc6",
            "ea854710df8d4b1593a49f1d38c6f8cd",
            "c8d1e558011d426082f13d6c5bac3d2c",
            "8093e307fa374c998c0e453f56152675",
            "75149f246e394d13ba57b4b08a5cbd9b",
            "73487af582de4c82b25f663b797536e7",
            "fb4a03652bb24e40b72bdd84567c52c6",
            "32a3b9b3a78f4178b893eced10e9cf0a",
            "c0a1c57635da4ca4ad0be9300a883387",
            "c2fe4bd46733475899c7c4f11c147c20",
            "873afcc1c3df40be85c62fb729875e12",
            "b457dce4ea8b4fb993bd1ba8b196724f",
            "0e16d6777fc24382b396105adacd6285",
            "419d2a7830eb49858d85428d969cd9b5",
            "149d084b407c46f1bc83ab5128d80293",
            "9c36ee96fef34124bcf4b1342f7e8012",
            "ff0a9b0d646848e0b2cbcf7c66637f88",
            "b82e196d8bcf4c9d832f593ef9af94f7",
            "2fcf701333b442caa1f776bd8cf1b574",
            "ca55751df4144b86aad2f6d6e9b381f4",
            "69b90d3413c5409cb4e726a33709c67e",
            "7073104b3a114e478dfb705ad1a5b0f6",
            "c7685443c7784c73b22cf15a39ccaa29",
            "fdf76ad6b4334ed19d921be10e47aea5",
            "5edcc44c556f43e782fad859e1cf5cb9",
            "cbe19988bc1044df9d1670a58d554f0e",
            "e5f2b7d41cb2418fbff8a7b60ecc3ef9",
            "ceda2ef6b4a44d3c8af19d3fe908a24f",
            "c949640e25574d1faceddb7eb8954673",
            "3af39f5b4fff4e7f8f13f22b3cd80dcd",
            "63b9673ef82849b1b6478a72aa29bada",
            "9d1ee288c4214d809ef3ee6b93deca17",
            "a812f639f9c249a79b7661783c3b350b",
            "894ccd8552c342dea79de650d464990c",
            "7dffe1376f6244f28ab1d9534d0dbc24",
            "52eb62637853483d864d1228c96b4789",
            "82754abaab134ea6846ae1b21e8bdbe1",
            "70592360f9264e9996d66c20e7cdb231"
          ]
        },
        "id": "MzepNpYXN7Qy",
        "outputId": "1016db5e-e500-46cc-9d08-cd635f2b4b66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbfd8561ec8d44f5b437fe8f8e74987a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69988315cf2646cf8a82ce0345489334",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73487af582de4c82b25f663b797536e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff0a9b0d646848e0b2cbcf7c66637f88",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceda2ef6b4a44d3c8af19d3fe908a24f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DistilBert model can also be tried with a few changes for further testing\n",
        "\n",
        "# from transformers import DistilBertTokenizer, DistilBertModel\n",
        "# bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "DZOTdfosimtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = df_train.SCORE.astype('int')\n",
        "train_text = df_train.SENTENCE\n",
        "\n",
        "y_validation = df_validate.SCORE.astype('int')\n",
        "X_validation = df_validate.SENTENCE"
      ],
      "metadata": {
        "id": "N4dZs1P5OEli"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_validation, test_text, y_validation, test_labels = train_test_split(X_validation, y_validation, \n",
        "                                                                random_state=2, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=y_validation)"
      ],
      "metadata": {
        "id": "WCGedPzJQvo6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning BERT for Text Classification"
      ],
      "metadata": {
        "id": "T-VqWm87OiUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this step, for faster computing max_length can be descresed. But, I believe P100 can handle with this. So, I am keeping it at 32\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 32,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    X_validation.tolist(),\n",
        "    max_length = 32,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 32,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkms0SgxOSvm",
        "outputId": "87fe739f-54a4-4c57-a658-16f1ae788dd0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we will convert the integer sequences to tensors.\n",
        "\n",
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(y_validation.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "metadata": {
        "id": "9ucyi7nQOqwD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create dataloaders for both train and validation set. These dataloaders will pass batches of train data and validation data as input to the model during the training phase"
      ],
      "metadata": {
        "id": "OJfKyCt3YrtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 4 # with better computers and higher RAM, this can be increased to 32 or 64\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "zVHoZ-pbYli5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Model Architecture**"
      ],
      "metadata": {
        "id": "6Lp5avmjYx0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Moving on we will now let’s define our model architecture\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,11)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,  return_dict=False)  \n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "3uUbRxEaZQIo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ekztPIsmZWAQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-4)         # learning rate"
      ],
      "metadata": {
        "id": "Mcz30_SuZj6Y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a class imbalance in our dataset. The majority of the SCOREs are 9 and 10. So, we will first compute class weights for the labels in the train set and then pass these weights to the loss function so that it takes care of the class imbalance."
      ],
      "metadata": {
        "id": "X1bLz0BTZrAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_labels),\n",
        "                                        y = train_labels                                                    \n",
        "                                    )\n",
        "class_weights_dic = dict(zip(np.unique(train_labels), class_weights)),\n",
        "class_weights_dic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQsoJpqXZrjo",
        "outputId": "c4166428-fd6e-4ea5-90a2-9a6619a2c3df"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 22.68482178614337,\n",
              "  1: 62.04162102957284,\n",
              "  2: 65.18296892980437,\n",
              "  3: 40.54688618468146,\n",
              "  4: 26.820075757575758,\n",
              "  5: 9.979563072586329,\n",
              "  6: 11.865102639296188,\n",
              "  7: 3.9702810681993412,\n",
              "  8: 1.4178013616339606,\n",
              "  9: 0.8286859583930714,\n",
              "  10: 0.11745214847192358},)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2fIYaTdbtvI",
        "outputId": "b18449d1-a0d6-4f02-b467-d2c5c0dd1775"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.68482179, 62.04162103, 65.18296893, 40.54688618, 26.82007576,\n",
              "        9.97956307, 11.86510264,  3.97028107,  1.41780136,  0.82868596,\n",
              "        0.11745215])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "dsTIg8JWbjuR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tune BERT**\n",
        "\n",
        "So, till now we have defined the model architecture, we have specified the optimizer and the loss function, and our dataloaders are also ready. Now we have to define a couple of functions to train (fine-tune) and evaluate the model, respectively."
      ],
      "metadata": {
        "id": "W4S_nn7mb_lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "4jz_5wfYcAqg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### We will use the following function to evaluate the model. It will use the validation set data."
      ],
      "metadata": {
        "id": "GL3ZZK_ucJZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from babel.dates import format_time\n",
        "from datetime import date, datetime, time"
      ],
      "metadata": {
        "id": "gXOOLBSv0jtk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    # if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "    #   # Calculate elapsed time in minutes.\n",
        "    #   elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "    #   # Report progress.\n",
        "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "6olvFh6gcKcA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Now we will finally start fine-tuning of the model.**"
      ],
      "metadata": {
        "id": "TezCMNxZcQ7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iieESSz0cT1Q",
        "outputId": "e49a8407-ef23-4f68-efa0-c2f3a9cdaada"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "  Batch    50  of  14,161.\n",
            "  Batch   100  of  14,161.\n",
            "  Batch   150  of  14,161.\n",
            "  Batch   200  of  14,161.\n",
            "  Batch   250  of  14,161.\n",
            "  Batch   300  of  14,161.\n",
            "  Batch   350  of  14,161.\n",
            "  Batch   400  of  14,161.\n",
            "  Batch   450  of  14,161.\n",
            "  Batch   500  of  14,161.\n",
            "  Batch   550  of  14,161.\n",
            "  Batch   600  of  14,161.\n",
            "  Batch   650  of  14,161.\n",
            "  Batch   700  of  14,161.\n",
            "  Batch   750  of  14,161.\n",
            "  Batch   800  of  14,161.\n",
            "  Batch   850  of  14,161.\n",
            "  Batch   900  of  14,161.\n",
            "  Batch   950  of  14,161.\n",
            "  Batch 1,000  of  14,161.\n",
            "  Batch 1,050  of  14,161.\n",
            "  Batch 1,100  of  14,161.\n",
            "  Batch 1,150  of  14,161.\n",
            "  Batch 1,200  of  14,161.\n",
            "  Batch 1,250  of  14,161.\n",
            "  Batch 1,300  of  14,161.\n",
            "  Batch 1,350  of  14,161.\n",
            "  Batch 1,400  of  14,161.\n",
            "  Batch 1,450  of  14,161.\n",
            "  Batch 1,500  of  14,161.\n",
            "  Batch 1,550  of  14,161.\n",
            "  Batch 1,600  of  14,161.\n",
            "  Batch 1,650  of  14,161.\n",
            "  Batch 1,700  of  14,161.\n",
            "  Batch 1,750  of  14,161.\n",
            "  Batch 1,800  of  14,161.\n",
            "  Batch 1,850  of  14,161.\n",
            "  Batch 1,900  of  14,161.\n",
            "  Batch 1,950  of  14,161.\n",
            "  Batch 2,000  of  14,161.\n",
            "  Batch 2,050  of  14,161.\n",
            "  Batch 2,100  of  14,161.\n",
            "  Batch 2,150  of  14,161.\n",
            "  Batch 2,200  of  14,161.\n",
            "  Batch 2,250  of  14,161.\n",
            "  Batch 2,300  of  14,161.\n",
            "  Batch 2,350  of  14,161.\n",
            "  Batch 2,400  of  14,161.\n",
            "  Batch 2,450  of  14,161.\n",
            "  Batch 2,500  of  14,161.\n",
            "  Batch 2,550  of  14,161.\n",
            "  Batch 2,600  of  14,161.\n",
            "  Batch 2,650  of  14,161.\n",
            "  Batch 2,700  of  14,161.\n",
            "  Batch 2,750  of  14,161.\n",
            "  Batch 2,800  of  14,161.\n",
            "  Batch 2,850  of  14,161.\n",
            "  Batch 2,900  of  14,161.\n",
            "  Batch 2,950  of  14,161.\n",
            "  Batch 3,000  of  14,161.\n",
            "  Batch 3,050  of  14,161.\n",
            "  Batch 3,100  of  14,161.\n",
            "  Batch 3,150  of  14,161.\n",
            "  Batch 3,200  of  14,161.\n",
            "  Batch 3,250  of  14,161.\n",
            "  Batch 3,300  of  14,161.\n",
            "  Batch 3,350  of  14,161.\n",
            "  Batch 3,400  of  14,161.\n",
            "  Batch 3,450  of  14,161.\n",
            "  Batch 3,500  of  14,161.\n",
            "  Batch 3,550  of  14,161.\n",
            "  Batch 3,600  of  14,161.\n",
            "  Batch 3,650  of  14,161.\n",
            "  Batch 3,700  of  14,161.\n",
            "  Batch 3,750  of  14,161.\n",
            "  Batch 3,800  of  14,161.\n",
            "  Batch 3,850  of  14,161.\n",
            "  Batch 3,900  of  14,161.\n",
            "  Batch 3,950  of  14,161.\n",
            "  Batch 4,000  of  14,161.\n",
            "  Batch 4,050  of  14,161.\n",
            "  Batch 4,100  of  14,161.\n",
            "  Batch 4,150  of  14,161.\n",
            "  Batch 4,200  of  14,161.\n",
            "  Batch 4,250  of  14,161.\n",
            "  Batch 4,300  of  14,161.\n",
            "  Batch 4,350  of  14,161.\n",
            "  Batch 4,400  of  14,161.\n",
            "  Batch 4,450  of  14,161.\n",
            "  Batch 4,500  of  14,161.\n",
            "  Batch 4,550  of  14,161.\n",
            "  Batch 4,600  of  14,161.\n",
            "  Batch 4,650  of  14,161.\n",
            "  Batch 4,700  of  14,161.\n",
            "  Batch 4,750  of  14,161.\n",
            "  Batch 4,800  of  14,161.\n",
            "  Batch 4,850  of  14,161.\n",
            "  Batch 4,900  of  14,161.\n",
            "  Batch 4,950  of  14,161.\n",
            "  Batch 5,000  of  14,161.\n",
            "  Batch 5,050  of  14,161.\n",
            "  Batch 5,100  of  14,161.\n",
            "  Batch 5,150  of  14,161.\n",
            "  Batch 5,200  of  14,161.\n",
            "  Batch 5,250  of  14,161.\n",
            "  Batch 5,300  of  14,161.\n",
            "  Batch 5,350  of  14,161.\n",
            "  Batch 5,400  of  14,161.\n",
            "  Batch 5,450  of  14,161.\n",
            "  Batch 5,500  of  14,161.\n",
            "  Batch 5,550  of  14,161.\n",
            "  Batch 5,600  of  14,161.\n",
            "  Batch 5,650  of  14,161.\n",
            "  Batch 5,700  of  14,161.\n",
            "  Batch 5,750  of  14,161.\n",
            "  Batch 5,800  of  14,161.\n",
            "  Batch 5,850  of  14,161.\n",
            "  Batch 5,900  of  14,161.\n",
            "  Batch 5,950  of  14,161.\n",
            "  Batch 6,000  of  14,161.\n",
            "  Batch 6,050  of  14,161.\n",
            "  Batch 6,100  of  14,161.\n",
            "  Batch 6,150  of  14,161.\n",
            "  Batch 6,200  of  14,161.\n",
            "  Batch 6,250  of  14,161.\n",
            "  Batch 6,300  of  14,161.\n",
            "  Batch 6,350  of  14,161.\n",
            "  Batch 6,400  of  14,161.\n",
            "  Batch 6,450  of  14,161.\n",
            "  Batch 6,500  of  14,161.\n",
            "  Batch 6,550  of  14,161.\n",
            "  Batch 6,600  of  14,161.\n",
            "  Batch 6,650  of  14,161.\n",
            "  Batch 6,700  of  14,161.\n",
            "  Batch 6,750  of  14,161.\n",
            "  Batch 6,800  of  14,161.\n",
            "  Batch 6,850  of  14,161.\n",
            "  Batch 6,900  of  14,161.\n",
            "  Batch 6,950  of  14,161.\n",
            "  Batch 7,000  of  14,161.\n",
            "  Batch 7,050  of  14,161.\n",
            "  Batch 7,100  of  14,161.\n",
            "  Batch 7,150  of  14,161.\n",
            "  Batch 7,200  of  14,161.\n",
            "  Batch 7,250  of  14,161.\n",
            "  Batch 7,300  of  14,161.\n",
            "  Batch 7,350  of  14,161.\n",
            "  Batch 7,400  of  14,161.\n",
            "  Batch 7,450  of  14,161.\n",
            "  Batch 7,500  of  14,161.\n",
            "  Batch 7,550  of  14,161.\n",
            "  Batch 7,600  of  14,161.\n",
            "  Batch 7,650  of  14,161.\n",
            "  Batch 7,700  of  14,161.\n",
            "  Batch 7,750  of  14,161.\n",
            "  Batch 7,800  of  14,161.\n",
            "  Batch 7,850  of  14,161.\n",
            "  Batch 7,900  of  14,161.\n",
            "  Batch 7,950  of  14,161.\n",
            "  Batch 8,000  of  14,161.\n",
            "  Batch 8,050  of  14,161.\n",
            "  Batch 8,100  of  14,161.\n",
            "  Batch 8,150  of  14,161.\n",
            "  Batch 8,200  of  14,161.\n",
            "  Batch 8,250  of  14,161.\n",
            "  Batch 8,300  of  14,161.\n",
            "  Batch 8,350  of  14,161.\n",
            "  Batch 8,400  of  14,161.\n",
            "  Batch 8,450  of  14,161.\n",
            "  Batch 8,500  of  14,161.\n",
            "  Batch 8,550  of  14,161.\n",
            "  Batch 8,600  of  14,161.\n",
            "  Batch 8,650  of  14,161.\n",
            "  Batch 8,700  of  14,161.\n",
            "  Batch 8,750  of  14,161.\n",
            "  Batch 8,800  of  14,161.\n",
            "  Batch 8,850  of  14,161.\n",
            "  Batch 8,900  of  14,161.\n",
            "  Batch 8,950  of  14,161.\n",
            "  Batch 9,000  of  14,161.\n",
            "  Batch 9,050  of  14,161.\n",
            "  Batch 9,100  of  14,161.\n",
            "  Batch 9,150  of  14,161.\n",
            "  Batch 9,200  of  14,161.\n",
            "  Batch 9,250  of  14,161.\n",
            "  Batch 9,300  of  14,161.\n",
            "  Batch 9,350  of  14,161.\n",
            "  Batch 9,400  of  14,161.\n",
            "  Batch 9,450  of  14,161.\n",
            "  Batch 9,500  of  14,161.\n",
            "  Batch 9,550  of  14,161.\n",
            "  Batch 9,600  of  14,161.\n",
            "  Batch 9,650  of  14,161.\n",
            "  Batch 9,700  of  14,161.\n",
            "  Batch 9,750  of  14,161.\n",
            "  Batch 9,800  of  14,161.\n",
            "  Batch 9,850  of  14,161.\n",
            "  Batch 9,900  of  14,161.\n",
            "  Batch 9,950  of  14,161.\n",
            "  Batch 10,000  of  14,161.\n",
            "  Batch 10,050  of  14,161.\n",
            "  Batch 10,100  of  14,161.\n",
            "  Batch 10,150  of  14,161.\n",
            "  Batch 10,200  of  14,161.\n",
            "  Batch 10,250  of  14,161.\n",
            "  Batch 10,300  of  14,161.\n",
            "  Batch 10,350  of  14,161.\n",
            "  Batch 10,400  of  14,161.\n",
            "  Batch 10,450  of  14,161.\n",
            "  Batch 10,500  of  14,161.\n",
            "  Batch 10,550  of  14,161.\n",
            "  Batch 10,600  of  14,161.\n",
            "  Batch 10,650  of  14,161.\n",
            "  Batch 10,700  of  14,161.\n",
            "  Batch 10,750  of  14,161.\n",
            "  Batch 10,800  of  14,161.\n",
            "  Batch 10,850  of  14,161.\n",
            "  Batch 10,900  of  14,161.\n",
            "  Batch 10,950  of  14,161.\n",
            "  Batch 11,000  of  14,161.\n",
            "  Batch 11,050  of  14,161.\n",
            "  Batch 11,100  of  14,161.\n",
            "  Batch 11,150  of  14,161.\n",
            "  Batch 11,200  of  14,161.\n",
            "  Batch 11,250  of  14,161.\n",
            "  Batch 11,300  of  14,161.\n",
            "  Batch 11,350  of  14,161.\n",
            "  Batch 11,400  of  14,161.\n",
            "  Batch 11,450  of  14,161.\n",
            "  Batch 11,500  of  14,161.\n",
            "  Batch 11,550  of  14,161.\n",
            "  Batch 11,600  of  14,161.\n",
            "  Batch 11,650  of  14,161.\n",
            "  Batch 11,700  of  14,161.\n",
            "  Batch 11,750  of  14,161.\n",
            "  Batch 11,800  of  14,161.\n",
            "  Batch 11,850  of  14,161.\n",
            "  Batch 11,900  of  14,161.\n",
            "  Batch 11,950  of  14,161.\n",
            "  Batch 12,000  of  14,161.\n",
            "  Batch 12,050  of  14,161.\n",
            "  Batch 12,100  of  14,161.\n",
            "  Batch 12,150  of  14,161.\n",
            "  Batch 12,200  of  14,161.\n",
            "  Batch 12,250  of  14,161.\n",
            "  Batch 12,300  of  14,161.\n",
            "  Batch 12,350  of  14,161.\n",
            "  Batch 12,400  of  14,161.\n",
            "  Batch 12,450  of  14,161.\n",
            "  Batch 12,500  of  14,161.\n",
            "  Batch 12,550  of  14,161.\n",
            "  Batch 12,600  of  14,161.\n",
            "  Batch 12,650  of  14,161.\n",
            "  Batch 12,700  of  14,161.\n",
            "  Batch 12,750  of  14,161.\n",
            "  Batch 12,800  of  14,161.\n",
            "  Batch 12,850  of  14,161.\n",
            "  Batch 12,900  of  14,161.\n",
            "  Batch 12,950  of  14,161.\n",
            "  Batch 13,000  of  14,161.\n",
            "  Batch 13,050  of  14,161.\n",
            "  Batch 13,100  of  14,161.\n",
            "  Batch 13,150  of  14,161.\n",
            "  Batch 13,200  of  14,161.\n",
            "  Batch 13,250  of  14,161.\n",
            "  Batch 13,300  of  14,161.\n",
            "  Batch 13,350  of  14,161.\n",
            "  Batch 13,400  of  14,161.\n",
            "  Batch 13,450  of  14,161.\n",
            "  Batch 13,500  of  14,161.\n",
            "  Batch 13,550  of  14,161.\n",
            "  Batch 13,600  of  14,161.\n",
            "  Batch 13,650  of  14,161.\n",
            "  Batch 13,700  of  14,161.\n",
            "  Batch 13,750  of  14,161.\n",
            "  Batch 13,800  of  14,161.\n",
            "  Batch 13,850  of  14,161.\n",
            "  Batch 13,900  of  14,161.\n",
            "  Batch 13,950  of  14,161.\n",
            "  Batch 14,000  of  14,161.\n",
            "  Batch 14,050  of  14,161.\n",
            "  Batch 14,100  of  14,161.\n",
            "  Batch 14,150  of  14,161.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.656\n",
            "Validation Loss: 1.701\n",
            "\n",
            " Epoch 2 / 5\n",
            "  Batch    50  of  14,161.\n",
            "  Batch   100  of  14,161.\n",
            "  Batch   150  of  14,161.\n",
            "  Batch   200  of  14,161.\n",
            "  Batch   250  of  14,161.\n",
            "  Batch   300  of  14,161.\n",
            "  Batch   350  of  14,161.\n",
            "  Batch   400  of  14,161.\n",
            "  Batch   450  of  14,161.\n",
            "  Batch   500  of  14,161.\n",
            "  Batch   550  of  14,161.\n",
            "  Batch   600  of  14,161.\n",
            "  Batch   650  of  14,161.\n",
            "  Batch   700  of  14,161.\n",
            "  Batch   750  of  14,161.\n",
            "  Batch   800  of  14,161.\n",
            "  Batch   850  of  14,161.\n",
            "  Batch   900  of  14,161.\n",
            "  Batch   950  of  14,161.\n",
            "  Batch 1,000  of  14,161.\n",
            "  Batch 1,050  of  14,161.\n",
            "  Batch 1,100  of  14,161.\n",
            "  Batch 1,150  of  14,161.\n",
            "  Batch 1,200  of  14,161.\n",
            "  Batch 1,250  of  14,161.\n",
            "  Batch 1,300  of  14,161.\n",
            "  Batch 1,350  of  14,161.\n",
            "  Batch 1,400  of  14,161.\n",
            "  Batch 1,450  of  14,161.\n",
            "  Batch 1,500  of  14,161.\n",
            "  Batch 1,550  of  14,161.\n",
            "  Batch 1,600  of  14,161.\n",
            "  Batch 1,650  of  14,161.\n",
            "  Batch 1,700  of  14,161.\n",
            "  Batch 1,750  of  14,161.\n",
            "  Batch 1,800  of  14,161.\n",
            "  Batch 1,850  of  14,161.\n",
            "  Batch 1,900  of  14,161.\n",
            "  Batch 1,950  of  14,161.\n",
            "  Batch 2,000  of  14,161.\n",
            "  Batch 2,050  of  14,161.\n",
            "  Batch 2,100  of  14,161.\n",
            "  Batch 2,150  of  14,161.\n",
            "  Batch 2,200  of  14,161.\n",
            "  Batch 2,250  of  14,161.\n",
            "  Batch 2,300  of  14,161.\n",
            "  Batch 2,350  of  14,161.\n",
            "  Batch 2,400  of  14,161.\n",
            "  Batch 2,450  of  14,161.\n",
            "  Batch 2,500  of  14,161.\n",
            "  Batch 2,550  of  14,161.\n",
            "  Batch 2,600  of  14,161.\n",
            "  Batch 2,650  of  14,161.\n",
            "  Batch 2,700  of  14,161.\n",
            "  Batch 2,750  of  14,161.\n",
            "  Batch 2,800  of  14,161.\n",
            "  Batch 2,850  of  14,161.\n",
            "  Batch 2,900  of  14,161.\n",
            "  Batch 2,950  of  14,161.\n",
            "  Batch 3,000  of  14,161.\n",
            "  Batch 3,050  of  14,161.\n",
            "  Batch 3,100  of  14,161.\n",
            "  Batch 3,150  of  14,161.\n",
            "  Batch 3,200  of  14,161.\n",
            "  Batch 3,250  of  14,161.\n",
            "  Batch 3,300  of  14,161.\n",
            "  Batch 3,350  of  14,161.\n",
            "  Batch 3,400  of  14,161.\n",
            "  Batch 3,450  of  14,161.\n",
            "  Batch 3,500  of  14,161.\n",
            "  Batch 3,550  of  14,161.\n",
            "  Batch 3,600  of  14,161.\n",
            "  Batch 3,650  of  14,161.\n",
            "  Batch 3,700  of  14,161.\n",
            "  Batch 3,750  of  14,161.\n",
            "  Batch 3,800  of  14,161.\n",
            "  Batch 3,850  of  14,161.\n",
            "  Batch 3,900  of  14,161.\n",
            "  Batch 3,950  of  14,161.\n",
            "  Batch 4,000  of  14,161.\n",
            "  Batch 4,050  of  14,161.\n",
            "  Batch 4,100  of  14,161.\n",
            "  Batch 4,150  of  14,161.\n",
            "  Batch 4,200  of  14,161.\n",
            "  Batch 4,250  of  14,161.\n",
            "  Batch 4,300  of  14,161.\n",
            "  Batch 4,350  of  14,161.\n",
            "  Batch 4,400  of  14,161.\n",
            "  Batch 4,450  of  14,161.\n",
            "  Batch 4,500  of  14,161.\n",
            "  Batch 4,550  of  14,161.\n",
            "  Batch 4,600  of  14,161.\n",
            "  Batch 4,650  of  14,161.\n",
            "  Batch 4,700  of  14,161.\n",
            "  Batch 4,750  of  14,161.\n",
            "  Batch 4,800  of  14,161.\n",
            "  Batch 4,850  of  14,161.\n",
            "  Batch 4,900  of  14,161.\n",
            "  Batch 4,950  of  14,161.\n",
            "  Batch 5,000  of  14,161.\n",
            "  Batch 5,050  of  14,161.\n",
            "  Batch 5,100  of  14,161.\n",
            "  Batch 5,150  of  14,161.\n",
            "  Batch 5,200  of  14,161.\n",
            "  Batch 5,250  of  14,161.\n",
            "  Batch 5,300  of  14,161.\n",
            "  Batch 5,350  of  14,161.\n",
            "  Batch 5,400  of  14,161.\n",
            "  Batch 5,450  of  14,161.\n",
            "  Batch 5,500  of  14,161.\n",
            "  Batch 5,550  of  14,161.\n",
            "  Batch 5,600  of  14,161.\n",
            "  Batch 5,650  of  14,161.\n",
            "  Batch 5,700  of  14,161.\n",
            "  Batch 5,750  of  14,161.\n",
            "  Batch 5,800  of  14,161.\n",
            "  Batch 5,850  of  14,161.\n",
            "  Batch 5,900  of  14,161.\n",
            "  Batch 5,950  of  14,161.\n",
            "  Batch 6,000  of  14,161.\n",
            "  Batch 6,050  of  14,161.\n",
            "  Batch 6,100  of  14,161.\n",
            "  Batch 6,150  of  14,161.\n",
            "  Batch 6,200  of  14,161.\n",
            "  Batch 6,250  of  14,161.\n",
            "  Batch 6,300  of  14,161.\n",
            "  Batch 6,350  of  14,161.\n",
            "  Batch 6,400  of  14,161.\n",
            "  Batch 6,450  of  14,161.\n",
            "  Batch 6,500  of  14,161.\n",
            "  Batch 6,550  of  14,161.\n",
            "  Batch 6,600  of  14,161.\n",
            "  Batch 6,650  of  14,161.\n",
            "  Batch 6,700  of  14,161.\n",
            "  Batch 6,750  of  14,161.\n",
            "  Batch 6,800  of  14,161.\n",
            "  Batch 6,850  of  14,161.\n",
            "  Batch 6,900  of  14,161.\n",
            "  Batch 6,950  of  14,161.\n",
            "  Batch 7,000  of  14,161.\n",
            "  Batch 7,050  of  14,161.\n",
            "  Batch 7,100  of  14,161.\n",
            "  Batch 7,150  of  14,161.\n",
            "  Batch 7,200  of  14,161.\n",
            "  Batch 7,250  of  14,161.\n",
            "  Batch 7,300  of  14,161.\n",
            "  Batch 7,350  of  14,161.\n",
            "  Batch 7,400  of  14,161.\n",
            "  Batch 7,450  of  14,161.\n",
            "  Batch 7,500  of  14,161.\n",
            "  Batch 7,550  of  14,161.\n",
            "  Batch 7,600  of  14,161.\n",
            "  Batch 7,650  of  14,161.\n",
            "  Batch 7,700  of  14,161.\n",
            "  Batch 7,750  of  14,161.\n",
            "  Batch 7,800  of  14,161.\n",
            "  Batch 7,850  of  14,161.\n",
            "  Batch 7,900  of  14,161.\n",
            "  Batch 7,950  of  14,161.\n",
            "  Batch 8,000  of  14,161.\n",
            "  Batch 8,050  of  14,161.\n",
            "  Batch 8,100  of  14,161.\n",
            "  Batch 8,150  of  14,161.\n",
            "  Batch 8,200  of  14,161.\n",
            "  Batch 8,250  of  14,161.\n",
            "  Batch 8,300  of  14,161.\n",
            "  Batch 8,350  of  14,161.\n",
            "  Batch 8,400  of  14,161.\n",
            "  Batch 8,450  of  14,161.\n",
            "  Batch 8,500  of  14,161.\n",
            "  Batch 8,550  of  14,161.\n",
            "  Batch 8,600  of  14,161.\n",
            "  Batch 8,650  of  14,161.\n",
            "  Batch 8,700  of  14,161.\n",
            "  Batch 8,750  of  14,161.\n",
            "  Batch 8,800  of  14,161.\n",
            "  Batch 8,850  of  14,161.\n",
            "  Batch 8,900  of  14,161.\n",
            "  Batch 8,950  of  14,161.\n",
            "  Batch 9,000  of  14,161.\n",
            "  Batch 9,050  of  14,161.\n",
            "  Batch 9,100  of  14,161.\n",
            "  Batch 9,150  of  14,161.\n",
            "  Batch 9,200  of  14,161.\n",
            "  Batch 9,250  of  14,161.\n",
            "  Batch 9,300  of  14,161.\n",
            "  Batch 9,350  of  14,161.\n",
            "  Batch 9,400  of  14,161.\n",
            "  Batch 9,450  of  14,161.\n",
            "  Batch 9,500  of  14,161.\n",
            "  Batch 9,550  of  14,161.\n",
            "  Batch 9,600  of  14,161.\n",
            "  Batch 9,650  of  14,161.\n",
            "  Batch 9,700  of  14,161.\n",
            "  Batch 9,750  of  14,161.\n",
            "  Batch 9,800  of  14,161.\n",
            "  Batch 9,850  of  14,161.\n",
            "  Batch 9,900  of  14,161.\n",
            "  Batch 9,950  of  14,161.\n",
            "  Batch 10,000  of  14,161.\n",
            "  Batch 10,050  of  14,161.\n",
            "  Batch 10,100  of  14,161.\n",
            "  Batch 10,150  of  14,161.\n",
            "  Batch 10,200  of  14,161.\n",
            "  Batch 10,250  of  14,161.\n",
            "  Batch 10,300  of  14,161.\n",
            "  Batch 10,350  of  14,161.\n",
            "  Batch 10,400  of  14,161.\n",
            "  Batch 10,450  of  14,161.\n",
            "  Batch 10,500  of  14,161.\n",
            "  Batch 10,550  of  14,161.\n",
            "  Batch 10,600  of  14,161.\n",
            "  Batch 10,650  of  14,161.\n",
            "  Batch 10,700  of  14,161.\n",
            "  Batch 10,750  of  14,161.\n",
            "  Batch 10,800  of  14,161.\n",
            "  Batch 10,850  of  14,161.\n",
            "  Batch 10,900  of  14,161.\n",
            "  Batch 10,950  of  14,161.\n",
            "  Batch 11,000  of  14,161.\n",
            "  Batch 11,050  of  14,161.\n",
            "  Batch 11,100  of  14,161.\n",
            "  Batch 11,150  of  14,161.\n",
            "  Batch 11,200  of  14,161.\n",
            "  Batch 11,250  of  14,161.\n",
            "  Batch 11,300  of  14,161.\n",
            "  Batch 11,350  of  14,161.\n",
            "  Batch 11,400  of  14,161.\n",
            "  Batch 11,450  of  14,161.\n",
            "  Batch 11,500  of  14,161.\n",
            "  Batch 11,550  of  14,161.\n",
            "  Batch 11,600  of  14,161.\n",
            "  Batch 11,650  of  14,161.\n",
            "  Batch 11,700  of  14,161.\n",
            "  Batch 11,750  of  14,161.\n",
            "  Batch 11,800  of  14,161.\n",
            "  Batch 11,850  of  14,161.\n",
            "  Batch 11,900  of  14,161.\n",
            "  Batch 11,950  of  14,161.\n",
            "  Batch 12,000  of  14,161.\n",
            "  Batch 12,050  of  14,161.\n",
            "  Batch 12,100  of  14,161.\n",
            "  Batch 12,150  of  14,161.\n",
            "  Batch 12,200  of  14,161.\n",
            "  Batch 12,250  of  14,161.\n",
            "  Batch 12,300  of  14,161.\n",
            "  Batch 12,350  of  14,161.\n",
            "  Batch 12,400  of  14,161.\n",
            "  Batch 12,450  of  14,161.\n",
            "  Batch 12,500  of  14,161.\n",
            "  Batch 12,550  of  14,161.\n",
            "  Batch 12,600  of  14,161.\n",
            "  Batch 12,650  of  14,161.\n",
            "  Batch 12,700  of  14,161.\n",
            "  Batch 12,750  of  14,161.\n",
            "  Batch 12,800  of  14,161.\n",
            "  Batch 12,850  of  14,161.\n",
            "  Batch 12,900  of  14,161.\n",
            "  Batch 12,950  of  14,161.\n",
            "  Batch 13,000  of  14,161.\n",
            "  Batch 13,050  of  14,161.\n",
            "  Batch 13,100  of  14,161.\n",
            "  Batch 13,150  of  14,161.\n",
            "  Batch 13,200  of  14,161.\n",
            "  Batch 13,250  of  14,161.\n",
            "  Batch 13,300  of  14,161.\n",
            "  Batch 13,350  of  14,161.\n",
            "  Batch 13,400  of  14,161.\n",
            "  Batch 13,450  of  14,161.\n",
            "  Batch 13,500  of  14,161.\n",
            "  Batch 13,550  of  14,161.\n",
            "  Batch 13,600  of  14,161.\n",
            "  Batch 13,650  of  14,161.\n",
            "  Batch 13,700  of  14,161.\n",
            "  Batch 13,750  of  14,161.\n",
            "  Batch 13,800  of  14,161.\n",
            "  Batch 13,850  of  14,161.\n",
            "  Batch 13,900  of  14,161.\n",
            "  Batch 13,950  of  14,161.\n",
            "  Batch 14,000  of  14,161.\n",
            "  Batch 14,050  of  14,161.\n",
            "  Batch 14,100  of  14,161.\n",
            "  Batch 14,150  of  14,161.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.648\n",
            "Validation Loss: 1.548\n",
            "\n",
            " Epoch 3 / 5\n",
            "  Batch    50  of  14,161.\n",
            "  Batch   100  of  14,161.\n",
            "  Batch   150  of  14,161.\n",
            "  Batch   200  of  14,161.\n",
            "  Batch   250  of  14,161.\n",
            "  Batch   300  of  14,161.\n",
            "  Batch   350  of  14,161.\n",
            "  Batch   400  of  14,161.\n",
            "  Batch   450  of  14,161.\n",
            "  Batch   500  of  14,161.\n",
            "  Batch   550  of  14,161.\n",
            "  Batch   600  of  14,161.\n",
            "  Batch   650  of  14,161.\n",
            "  Batch   700  of  14,161.\n",
            "  Batch   750  of  14,161.\n",
            "  Batch   800  of  14,161.\n",
            "  Batch   850  of  14,161.\n",
            "  Batch   900  of  14,161.\n",
            "  Batch   950  of  14,161.\n",
            "  Batch 1,000  of  14,161.\n",
            "  Batch 1,050  of  14,161.\n",
            "  Batch 1,100  of  14,161.\n",
            "  Batch 1,150  of  14,161.\n",
            "  Batch 1,200  of  14,161.\n",
            "  Batch 1,250  of  14,161.\n",
            "  Batch 1,300  of  14,161.\n",
            "  Batch 1,350  of  14,161.\n",
            "  Batch 1,400  of  14,161.\n",
            "  Batch 1,450  of  14,161.\n",
            "  Batch 1,500  of  14,161.\n",
            "  Batch 1,550  of  14,161.\n",
            "  Batch 1,600  of  14,161.\n",
            "  Batch 1,650  of  14,161.\n",
            "  Batch 1,700  of  14,161.\n",
            "  Batch 1,750  of  14,161.\n",
            "  Batch 1,800  of  14,161.\n",
            "  Batch 1,850  of  14,161.\n",
            "  Batch 1,900  of  14,161.\n",
            "  Batch 1,950  of  14,161.\n",
            "  Batch 2,000  of  14,161.\n",
            "  Batch 2,050  of  14,161.\n",
            "  Batch 2,100  of  14,161.\n",
            "  Batch 2,150  of  14,161.\n",
            "  Batch 2,200  of  14,161.\n",
            "  Batch 2,250  of  14,161.\n",
            "  Batch 2,300  of  14,161.\n",
            "  Batch 2,350  of  14,161.\n",
            "  Batch 2,400  of  14,161.\n",
            "  Batch 2,450  of  14,161.\n",
            "  Batch 2,500  of  14,161.\n",
            "  Batch 2,550  of  14,161.\n",
            "  Batch 2,600  of  14,161.\n",
            "  Batch 2,650  of  14,161.\n",
            "  Batch 2,700  of  14,161.\n",
            "  Batch 2,750  of  14,161.\n",
            "  Batch 2,800  of  14,161.\n",
            "  Batch 2,850  of  14,161.\n",
            "  Batch 2,900  of  14,161.\n",
            "  Batch 2,950  of  14,161.\n",
            "  Batch 3,000  of  14,161.\n",
            "  Batch 3,050  of  14,161.\n",
            "  Batch 3,100  of  14,161.\n",
            "  Batch 3,150  of  14,161.\n",
            "  Batch 3,200  of  14,161.\n",
            "  Batch 3,250  of  14,161.\n",
            "  Batch 3,300  of  14,161.\n",
            "  Batch 3,350  of  14,161.\n",
            "  Batch 3,400  of  14,161.\n",
            "  Batch 3,450  of  14,161.\n",
            "  Batch 3,500  of  14,161.\n",
            "  Batch 3,550  of  14,161.\n",
            "  Batch 3,600  of  14,161.\n",
            "  Batch 3,650  of  14,161.\n",
            "  Batch 3,700  of  14,161.\n",
            "  Batch 3,750  of  14,161.\n",
            "  Batch 3,800  of  14,161.\n",
            "  Batch 3,850  of  14,161.\n",
            "  Batch 3,900  of  14,161.\n",
            "  Batch 3,950  of  14,161.\n",
            "  Batch 4,000  of  14,161.\n",
            "  Batch 4,050  of  14,161.\n",
            "  Batch 4,100  of  14,161.\n",
            "  Batch 4,150  of  14,161.\n",
            "  Batch 4,200  of  14,161.\n",
            "  Batch 4,250  of  14,161.\n",
            "  Batch 4,300  of  14,161.\n",
            "  Batch 4,350  of  14,161.\n",
            "  Batch 4,400  of  14,161.\n",
            "  Batch 4,450  of  14,161.\n",
            "  Batch 4,500  of  14,161.\n",
            "  Batch 4,550  of  14,161.\n",
            "  Batch 4,600  of  14,161.\n",
            "  Batch 4,650  of  14,161.\n",
            "  Batch 4,700  of  14,161.\n",
            "  Batch 4,750  of  14,161.\n",
            "  Batch 4,800  of  14,161.\n",
            "  Batch 4,850  of  14,161.\n",
            "  Batch 4,900  of  14,161.\n",
            "  Batch 4,950  of  14,161.\n",
            "  Batch 5,000  of  14,161.\n",
            "  Batch 5,050  of  14,161.\n",
            "  Batch 5,100  of  14,161.\n",
            "  Batch 5,150  of  14,161.\n",
            "  Batch 5,200  of  14,161.\n",
            "  Batch 5,250  of  14,161.\n",
            "  Batch 5,300  of  14,161.\n",
            "  Batch 5,350  of  14,161.\n",
            "  Batch 5,400  of  14,161.\n",
            "  Batch 5,450  of  14,161.\n",
            "  Batch 5,500  of  14,161.\n",
            "  Batch 5,550  of  14,161.\n",
            "  Batch 5,600  of  14,161.\n",
            "  Batch 5,650  of  14,161.\n",
            "  Batch 5,700  of  14,161.\n",
            "  Batch 5,750  of  14,161.\n",
            "  Batch 5,800  of  14,161.\n",
            "  Batch 5,850  of  14,161.\n",
            "  Batch 5,900  of  14,161.\n",
            "  Batch 5,950  of  14,161.\n",
            "  Batch 6,000  of  14,161.\n",
            "  Batch 6,050  of  14,161.\n",
            "  Batch 6,100  of  14,161.\n",
            "  Batch 6,150  of  14,161.\n",
            "  Batch 6,200  of  14,161.\n",
            "  Batch 6,250  of  14,161.\n",
            "  Batch 6,300  of  14,161.\n",
            "  Batch 6,350  of  14,161.\n",
            "  Batch 6,400  of  14,161.\n",
            "  Batch 6,450  of  14,161.\n",
            "  Batch 6,500  of  14,161.\n",
            "  Batch 6,550  of  14,161.\n",
            "  Batch 6,600  of  14,161.\n",
            "  Batch 6,650  of  14,161.\n",
            "  Batch 6,700  of  14,161.\n",
            "  Batch 6,750  of  14,161.\n",
            "  Batch 6,800  of  14,161.\n",
            "  Batch 6,850  of  14,161.\n",
            "  Batch 6,900  of  14,161.\n",
            "  Batch 6,950  of  14,161.\n",
            "  Batch 7,000  of  14,161.\n",
            "  Batch 7,050  of  14,161.\n",
            "  Batch 7,100  of  14,161.\n",
            "  Batch 7,150  of  14,161.\n",
            "  Batch 7,200  of  14,161.\n",
            "  Batch 7,250  of  14,161.\n",
            "  Batch 7,300  of  14,161.\n",
            "  Batch 7,350  of  14,161.\n",
            "  Batch 7,400  of  14,161.\n",
            "  Batch 7,450  of  14,161.\n",
            "  Batch 7,500  of  14,161.\n",
            "  Batch 7,550  of  14,161.\n",
            "  Batch 7,600  of  14,161.\n",
            "  Batch 7,650  of  14,161.\n",
            "  Batch 7,700  of  14,161.\n",
            "  Batch 7,750  of  14,161.\n",
            "  Batch 7,800  of  14,161.\n",
            "  Batch 7,850  of  14,161.\n",
            "  Batch 7,900  of  14,161.\n",
            "  Batch 7,950  of  14,161.\n",
            "  Batch 8,000  of  14,161.\n",
            "  Batch 8,050  of  14,161.\n",
            "  Batch 8,100  of  14,161.\n",
            "  Batch 8,150  of  14,161.\n",
            "  Batch 8,200  of  14,161.\n",
            "  Batch 8,250  of  14,161.\n",
            "  Batch 8,300  of  14,161.\n",
            "  Batch 8,350  of  14,161.\n",
            "  Batch 8,400  of  14,161.\n",
            "  Batch 8,450  of  14,161.\n",
            "  Batch 8,500  of  14,161.\n",
            "  Batch 8,550  of  14,161.\n",
            "  Batch 8,600  of  14,161.\n",
            "  Batch 8,650  of  14,161.\n",
            "  Batch 8,700  of  14,161.\n",
            "  Batch 8,750  of  14,161.\n",
            "  Batch 8,800  of  14,161.\n",
            "  Batch 8,850  of  14,161.\n",
            "  Batch 8,900  of  14,161.\n",
            "  Batch 8,950  of  14,161.\n",
            "  Batch 9,000  of  14,161.\n",
            "  Batch 9,050  of  14,161.\n",
            "  Batch 9,100  of  14,161.\n",
            "  Batch 9,150  of  14,161.\n",
            "  Batch 9,200  of  14,161.\n",
            "  Batch 9,250  of  14,161.\n",
            "  Batch 9,300  of  14,161.\n",
            "  Batch 9,350  of  14,161.\n",
            "  Batch 9,400  of  14,161.\n",
            "  Batch 9,450  of  14,161.\n",
            "  Batch 9,500  of  14,161.\n",
            "  Batch 9,550  of  14,161.\n",
            "  Batch 9,600  of  14,161.\n",
            "  Batch 9,650  of  14,161.\n",
            "  Batch 9,700  of  14,161.\n",
            "  Batch 9,750  of  14,161.\n",
            "  Batch 9,800  of  14,161.\n",
            "  Batch 9,850  of  14,161.\n",
            "  Batch 9,900  of  14,161.\n",
            "  Batch 9,950  of  14,161.\n",
            "  Batch 10,000  of  14,161.\n",
            "  Batch 10,050  of  14,161.\n",
            "  Batch 10,100  of  14,161.\n",
            "  Batch 10,150  of  14,161.\n",
            "  Batch 10,200  of  14,161.\n",
            "  Batch 10,250  of  14,161.\n",
            "  Batch 10,300  of  14,161.\n",
            "  Batch 10,350  of  14,161.\n",
            "  Batch 10,400  of  14,161.\n",
            "  Batch 10,450  of  14,161.\n",
            "  Batch 10,500  of  14,161.\n",
            "  Batch 10,550  of  14,161.\n",
            "  Batch 10,600  of  14,161.\n",
            "  Batch 10,650  of  14,161.\n",
            "  Batch 10,700  of  14,161.\n",
            "  Batch 10,750  of  14,161.\n",
            "  Batch 10,800  of  14,161.\n",
            "  Batch 10,850  of  14,161.\n",
            "  Batch 10,900  of  14,161.\n",
            "  Batch 10,950  of  14,161.\n",
            "  Batch 11,000  of  14,161.\n",
            "  Batch 11,050  of  14,161.\n",
            "  Batch 11,100  of  14,161.\n",
            "  Batch 11,150  of  14,161.\n",
            "  Batch 11,200  of  14,161.\n",
            "  Batch 11,250  of  14,161.\n",
            "  Batch 11,300  of  14,161.\n",
            "  Batch 11,350  of  14,161.\n",
            "  Batch 11,400  of  14,161.\n",
            "  Batch 11,450  of  14,161.\n",
            "  Batch 11,500  of  14,161.\n",
            "  Batch 11,550  of  14,161.\n",
            "  Batch 11,600  of  14,161.\n",
            "  Batch 11,650  of  14,161.\n",
            "  Batch 11,700  of  14,161.\n",
            "  Batch 11,750  of  14,161.\n",
            "  Batch 11,800  of  14,161.\n",
            "  Batch 11,850  of  14,161.\n",
            "  Batch 11,900  of  14,161.\n",
            "  Batch 11,950  of  14,161.\n",
            "  Batch 12,000  of  14,161.\n",
            "  Batch 12,050  of  14,161.\n",
            "  Batch 12,100  of  14,161.\n",
            "  Batch 12,150  of  14,161.\n",
            "  Batch 12,200  of  14,161.\n",
            "  Batch 12,250  of  14,161.\n",
            "  Batch 12,300  of  14,161.\n",
            "  Batch 12,350  of  14,161.\n",
            "  Batch 12,400  of  14,161.\n",
            "  Batch 12,450  of  14,161.\n",
            "  Batch 12,500  of  14,161.\n",
            "  Batch 12,550  of  14,161.\n",
            "  Batch 12,600  of  14,161.\n",
            "  Batch 12,650  of  14,161.\n",
            "  Batch 12,700  of  14,161.\n",
            "  Batch 12,750  of  14,161.\n",
            "  Batch 12,800  of  14,161.\n",
            "  Batch 12,850  of  14,161.\n",
            "  Batch 12,900  of  14,161.\n",
            "  Batch 12,950  of  14,161.\n",
            "  Batch 13,000  of  14,161.\n",
            "  Batch 13,050  of  14,161.\n",
            "  Batch 13,100  of  14,161.\n",
            "  Batch 13,150  of  14,161.\n",
            "  Batch 13,200  of  14,161.\n",
            "  Batch 13,250  of  14,161.\n",
            "  Batch 13,300  of  14,161.\n",
            "  Batch 13,350  of  14,161.\n",
            "  Batch 13,400  of  14,161.\n",
            "  Batch 13,450  of  14,161.\n",
            "  Batch 13,500  of  14,161.\n",
            "  Batch 13,550  of  14,161.\n",
            "  Batch 13,600  of  14,161.\n",
            "  Batch 13,650  of  14,161.\n",
            "  Batch 13,700  of  14,161.\n",
            "  Batch 13,750  of  14,161.\n",
            "  Batch 13,800  of  14,161.\n",
            "  Batch 13,850  of  14,161.\n",
            "  Batch 13,900  of  14,161.\n",
            "  Batch 13,950  of  14,161.\n",
            "  Batch 14,000  of  14,161.\n",
            "  Batch 14,050  of  14,161.\n",
            "  Batch 14,100  of  14,161.\n",
            "  Batch 14,150  of  14,161.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.640\n",
            "Validation Loss: 1.675\n",
            "\n",
            " Epoch 4 / 5\n",
            "  Batch    50  of  14,161.\n",
            "  Batch   100  of  14,161.\n",
            "  Batch   150  of  14,161.\n",
            "  Batch   200  of  14,161.\n",
            "  Batch   250  of  14,161.\n",
            "  Batch   300  of  14,161.\n",
            "  Batch   350  of  14,161.\n",
            "  Batch   400  of  14,161.\n",
            "  Batch   450  of  14,161.\n",
            "  Batch   500  of  14,161.\n",
            "  Batch   550  of  14,161.\n",
            "  Batch   600  of  14,161.\n",
            "  Batch   650  of  14,161.\n",
            "  Batch   700  of  14,161.\n",
            "  Batch   750  of  14,161.\n",
            "  Batch   800  of  14,161.\n",
            "  Batch   850  of  14,161.\n",
            "  Batch   900  of  14,161.\n",
            "  Batch   950  of  14,161.\n",
            "  Batch 1,000  of  14,161.\n",
            "  Batch 1,050  of  14,161.\n",
            "  Batch 1,100  of  14,161.\n",
            "  Batch 1,150  of  14,161.\n",
            "  Batch 1,200  of  14,161.\n",
            "  Batch 1,250  of  14,161.\n",
            "  Batch 1,300  of  14,161.\n",
            "  Batch 1,350  of  14,161.\n",
            "  Batch 1,400  of  14,161.\n",
            "  Batch 1,450  of  14,161.\n",
            "  Batch 1,500  of  14,161.\n",
            "  Batch 1,550  of  14,161.\n",
            "  Batch 1,600  of  14,161.\n",
            "  Batch 1,650  of  14,161.\n",
            "  Batch 1,700  of  14,161.\n",
            "  Batch 1,750  of  14,161.\n",
            "  Batch 1,800  of  14,161.\n",
            "  Batch 1,850  of  14,161.\n",
            "  Batch 1,900  of  14,161.\n",
            "  Batch 1,950  of  14,161.\n",
            "  Batch 2,000  of  14,161.\n",
            "  Batch 2,050  of  14,161.\n",
            "  Batch 2,100  of  14,161.\n",
            "  Batch 2,150  of  14,161.\n",
            "  Batch 2,200  of  14,161.\n",
            "  Batch 2,250  of  14,161.\n",
            "  Batch 2,300  of  14,161.\n",
            "  Batch 2,350  of  14,161.\n",
            "  Batch 2,400  of  14,161.\n",
            "  Batch 2,450  of  14,161.\n",
            "  Batch 2,500  of  14,161.\n",
            "  Batch 2,550  of  14,161.\n",
            "  Batch 2,600  of  14,161.\n",
            "  Batch 2,650  of  14,161.\n",
            "  Batch 2,700  of  14,161.\n",
            "  Batch 2,750  of  14,161.\n",
            "  Batch 2,800  of  14,161.\n",
            "  Batch 2,850  of  14,161.\n",
            "  Batch 2,900  of  14,161.\n",
            "  Batch 2,950  of  14,161.\n",
            "  Batch 3,000  of  14,161.\n",
            "  Batch 3,050  of  14,161.\n",
            "  Batch 3,100  of  14,161.\n",
            "  Batch 3,150  of  14,161.\n",
            "  Batch 3,200  of  14,161.\n",
            "  Batch 3,250  of  14,161.\n",
            "  Batch 3,300  of  14,161.\n",
            "  Batch 3,350  of  14,161.\n",
            "  Batch 3,400  of  14,161.\n",
            "  Batch 3,450  of  14,161.\n",
            "  Batch 3,500  of  14,161.\n",
            "  Batch 3,550  of  14,161.\n",
            "  Batch 3,600  of  14,161.\n",
            "  Batch 3,650  of  14,161.\n",
            "  Batch 3,700  of  14,161.\n",
            "  Batch 3,750  of  14,161.\n",
            "  Batch 3,800  of  14,161.\n",
            "  Batch 3,850  of  14,161.\n",
            "  Batch 3,900  of  14,161.\n",
            "  Batch 3,950  of  14,161.\n",
            "  Batch 4,000  of  14,161.\n",
            "  Batch 4,050  of  14,161.\n",
            "  Batch 4,100  of  14,161.\n",
            "  Batch 4,150  of  14,161.\n",
            "  Batch 4,200  of  14,161.\n",
            "  Batch 4,250  of  14,161.\n",
            "  Batch 4,300  of  14,161.\n",
            "  Batch 4,350  of  14,161.\n",
            "  Batch 4,400  of  14,161.\n",
            "  Batch 4,450  of  14,161.\n",
            "  Batch 4,500  of  14,161.\n",
            "  Batch 4,550  of  14,161.\n",
            "  Batch 4,600  of  14,161.\n",
            "  Batch 4,650  of  14,161.\n",
            "  Batch 4,700  of  14,161.\n",
            "  Batch 4,750  of  14,161.\n",
            "  Batch 4,800  of  14,161.\n",
            "  Batch 4,850  of  14,161.\n",
            "  Batch 4,900  of  14,161.\n",
            "  Batch 4,950  of  14,161.\n",
            "  Batch 5,000  of  14,161.\n",
            "  Batch 5,050  of  14,161.\n",
            "  Batch 5,100  of  14,161.\n",
            "  Batch 5,150  of  14,161.\n",
            "  Batch 5,200  of  14,161.\n",
            "  Batch 5,250  of  14,161.\n",
            "  Batch 5,300  of  14,161.\n",
            "  Batch 5,350  of  14,161.\n",
            "  Batch 5,400  of  14,161.\n",
            "  Batch 5,450  of  14,161.\n",
            "  Batch 5,500  of  14,161.\n",
            "  Batch 5,550  of  14,161.\n",
            "  Batch 5,600  of  14,161.\n",
            "  Batch 5,650  of  14,161.\n",
            "  Batch 5,700  of  14,161.\n",
            "  Batch 5,750  of  14,161.\n",
            "  Batch 5,800  of  14,161.\n",
            "  Batch 5,850  of  14,161.\n",
            "  Batch 5,900  of  14,161.\n",
            "  Batch 5,950  of  14,161.\n",
            "  Batch 6,000  of  14,161.\n",
            "  Batch 6,050  of  14,161.\n",
            "  Batch 6,100  of  14,161.\n",
            "  Batch 6,150  of  14,161.\n",
            "  Batch 6,200  of  14,161.\n",
            "  Batch 6,250  of  14,161.\n",
            "  Batch 6,300  of  14,161.\n",
            "  Batch 6,350  of  14,161.\n",
            "  Batch 6,400  of  14,161.\n",
            "  Batch 6,450  of  14,161.\n",
            "  Batch 6,500  of  14,161.\n",
            "  Batch 6,550  of  14,161.\n",
            "  Batch 6,600  of  14,161.\n",
            "  Batch 6,650  of  14,161.\n",
            "  Batch 6,700  of  14,161.\n",
            "  Batch 6,750  of  14,161.\n",
            "  Batch 6,800  of  14,161.\n",
            "  Batch 6,850  of  14,161.\n",
            "  Batch 6,900  of  14,161.\n",
            "  Batch 6,950  of  14,161.\n",
            "  Batch 7,000  of  14,161.\n",
            "  Batch 7,050  of  14,161.\n",
            "  Batch 7,100  of  14,161.\n",
            "  Batch 7,150  of  14,161.\n",
            "  Batch 7,200  of  14,161.\n",
            "  Batch 7,250  of  14,161.\n",
            "  Batch 7,300  of  14,161.\n",
            "  Batch 7,350  of  14,161.\n",
            "  Batch 7,400  of  14,161.\n",
            "  Batch 7,450  of  14,161.\n",
            "  Batch 7,500  of  14,161.\n",
            "  Batch 7,550  of  14,161.\n",
            "  Batch 7,600  of  14,161.\n",
            "  Batch 7,650  of  14,161.\n",
            "  Batch 7,700  of  14,161.\n",
            "  Batch 7,750  of  14,161.\n",
            "  Batch 7,800  of  14,161.\n",
            "  Batch 7,850  of  14,161.\n",
            "  Batch 7,900  of  14,161.\n",
            "  Batch 7,950  of  14,161.\n",
            "  Batch 8,000  of  14,161.\n",
            "  Batch 8,050  of  14,161.\n",
            "  Batch 8,100  of  14,161.\n",
            "  Batch 8,150  of  14,161.\n",
            "  Batch 8,200  of  14,161.\n",
            "  Batch 8,250  of  14,161.\n",
            "  Batch 8,300  of  14,161.\n",
            "  Batch 8,350  of  14,161.\n",
            "  Batch 8,400  of  14,161.\n",
            "  Batch 8,450  of  14,161.\n",
            "  Batch 8,500  of  14,161.\n",
            "  Batch 8,550  of  14,161.\n",
            "  Batch 8,600  of  14,161.\n",
            "  Batch 8,650  of  14,161.\n",
            "  Batch 8,700  of  14,161.\n",
            "  Batch 8,750  of  14,161.\n",
            "  Batch 8,800  of  14,161.\n",
            "  Batch 8,850  of  14,161.\n",
            "  Batch 8,900  of  14,161.\n",
            "  Batch 8,950  of  14,161.\n",
            "  Batch 9,000  of  14,161.\n",
            "  Batch 9,050  of  14,161.\n",
            "  Batch 9,100  of  14,161.\n",
            "  Batch 9,150  of  14,161.\n",
            "  Batch 9,200  of  14,161.\n",
            "  Batch 9,250  of  14,161.\n",
            "  Batch 9,300  of  14,161.\n",
            "  Batch 9,350  of  14,161.\n",
            "  Batch 9,400  of  14,161.\n",
            "  Batch 9,450  of  14,161.\n",
            "  Batch 9,500  of  14,161.\n",
            "  Batch 9,550  of  14,161.\n",
            "  Batch 9,600  of  14,161.\n",
            "  Batch 9,650  of  14,161.\n",
            "  Batch 9,700  of  14,161.\n",
            "  Batch 9,750  of  14,161.\n",
            "  Batch 9,800  of  14,161.\n",
            "  Batch 9,850  of  14,161.\n",
            "  Batch 9,900  of  14,161.\n",
            "  Batch 9,950  of  14,161.\n",
            "  Batch 10,000  of  14,161.\n",
            "  Batch 10,050  of  14,161.\n",
            "  Batch 10,100  of  14,161.\n",
            "  Batch 10,150  of  14,161.\n",
            "  Batch 10,200  of  14,161.\n",
            "  Batch 10,250  of  14,161.\n",
            "  Batch 10,300  of  14,161.\n",
            "  Batch 10,350  of  14,161.\n",
            "  Batch 10,400  of  14,161.\n",
            "  Batch 10,450  of  14,161.\n",
            "  Batch 10,500  of  14,161.\n",
            "  Batch 10,550  of  14,161.\n",
            "  Batch 10,600  of  14,161.\n",
            "  Batch 10,650  of  14,161.\n",
            "  Batch 10,700  of  14,161.\n",
            "  Batch 10,750  of  14,161.\n",
            "  Batch 10,800  of  14,161.\n",
            "  Batch 10,850  of  14,161.\n",
            "  Batch 10,900  of  14,161.\n",
            "  Batch 10,950  of  14,161.\n",
            "  Batch 11,000  of  14,161.\n",
            "  Batch 11,050  of  14,161.\n",
            "  Batch 11,100  of  14,161.\n",
            "  Batch 11,150  of  14,161.\n",
            "  Batch 11,200  of  14,161.\n",
            "  Batch 11,250  of  14,161.\n",
            "  Batch 11,300  of  14,161.\n",
            "  Batch 11,350  of  14,161.\n",
            "  Batch 11,400  of  14,161.\n",
            "  Batch 11,450  of  14,161.\n",
            "  Batch 11,500  of  14,161.\n",
            "  Batch 11,550  of  14,161.\n",
            "  Batch 11,600  of  14,161.\n",
            "  Batch 11,650  of  14,161.\n",
            "  Batch 11,700  of  14,161.\n",
            "  Batch 11,750  of  14,161.\n",
            "  Batch 11,800  of  14,161.\n",
            "  Batch 11,850  of  14,161.\n",
            "  Batch 11,900  of  14,161.\n",
            "  Batch 11,950  of  14,161.\n",
            "  Batch 12,000  of  14,161.\n",
            "  Batch 12,050  of  14,161.\n",
            "  Batch 12,100  of  14,161.\n",
            "  Batch 12,150  of  14,161.\n",
            "  Batch 12,200  of  14,161.\n",
            "  Batch 12,250  of  14,161.\n",
            "  Batch 12,300  of  14,161.\n",
            "  Batch 12,350  of  14,161.\n",
            "  Batch 12,400  of  14,161.\n",
            "  Batch 12,450  of  14,161.\n",
            "  Batch 12,500  of  14,161.\n",
            "  Batch 12,550  of  14,161.\n",
            "  Batch 12,600  of  14,161.\n",
            "  Batch 12,650  of  14,161.\n",
            "  Batch 12,700  of  14,161.\n",
            "  Batch 12,750  of  14,161.\n",
            "  Batch 12,800  of  14,161.\n",
            "  Batch 12,850  of  14,161.\n",
            "  Batch 12,900  of  14,161.\n",
            "  Batch 12,950  of  14,161.\n",
            "  Batch 13,000  of  14,161.\n",
            "  Batch 13,050  of  14,161.\n",
            "  Batch 13,100  of  14,161.\n",
            "  Batch 13,150  of  14,161.\n",
            "  Batch 13,200  of  14,161.\n",
            "  Batch 13,250  of  14,161.\n",
            "  Batch 13,300  of  14,161.\n",
            "  Batch 13,350  of  14,161.\n",
            "  Batch 13,400  of  14,161.\n",
            "  Batch 13,450  of  14,161.\n",
            "  Batch 13,500  of  14,161.\n",
            "  Batch 13,550  of  14,161.\n",
            "  Batch 13,600  of  14,161.\n",
            "  Batch 13,650  of  14,161.\n",
            "  Batch 13,700  of  14,161.\n",
            "  Batch 13,750  of  14,161.\n",
            "  Batch 13,800  of  14,161.\n",
            "  Batch 13,850  of  14,161.\n",
            "  Batch 13,900  of  14,161.\n",
            "  Batch 13,950  of  14,161.\n",
            "  Batch 14,000  of  14,161.\n",
            "  Batch 14,050  of  14,161.\n",
            "  Batch 14,100  of  14,161.\n",
            "  Batch 14,150  of  14,161.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.640\n",
            "Validation Loss: 1.563\n",
            "\n",
            " Epoch 5 / 5\n",
            "  Batch    50  of  14,161.\n",
            "  Batch   100  of  14,161.\n",
            "  Batch   150  of  14,161.\n",
            "  Batch   200  of  14,161.\n",
            "  Batch   250  of  14,161.\n",
            "  Batch   300  of  14,161.\n",
            "  Batch   350  of  14,161.\n",
            "  Batch   400  of  14,161.\n",
            "  Batch   450  of  14,161.\n",
            "  Batch   500  of  14,161.\n",
            "  Batch   550  of  14,161.\n",
            "  Batch   600  of  14,161.\n",
            "  Batch   650  of  14,161.\n",
            "  Batch   700  of  14,161.\n",
            "  Batch   750  of  14,161.\n",
            "  Batch   800  of  14,161.\n",
            "  Batch   850  of  14,161.\n",
            "  Batch   900  of  14,161.\n",
            "  Batch   950  of  14,161.\n",
            "  Batch 1,000  of  14,161.\n",
            "  Batch 1,050  of  14,161.\n",
            "  Batch 1,100  of  14,161.\n",
            "  Batch 1,150  of  14,161.\n",
            "  Batch 1,200  of  14,161.\n",
            "  Batch 1,250  of  14,161.\n",
            "  Batch 1,300  of  14,161.\n",
            "  Batch 1,350  of  14,161.\n",
            "  Batch 1,400  of  14,161.\n",
            "  Batch 1,450  of  14,161.\n",
            "  Batch 1,500  of  14,161.\n",
            "  Batch 1,550  of  14,161.\n",
            "  Batch 1,600  of  14,161.\n",
            "  Batch 1,650  of  14,161.\n",
            "  Batch 1,700  of  14,161.\n",
            "  Batch 1,750  of  14,161.\n",
            "  Batch 1,800  of  14,161.\n",
            "  Batch 1,850  of  14,161.\n",
            "  Batch 1,900  of  14,161.\n",
            "  Batch 1,950  of  14,161.\n",
            "  Batch 2,000  of  14,161.\n",
            "  Batch 2,050  of  14,161.\n",
            "  Batch 2,100  of  14,161.\n",
            "  Batch 2,150  of  14,161.\n",
            "  Batch 2,200  of  14,161.\n",
            "  Batch 2,250  of  14,161.\n",
            "  Batch 2,300  of  14,161.\n",
            "  Batch 2,350  of  14,161.\n",
            "  Batch 2,400  of  14,161.\n",
            "  Batch 2,450  of  14,161.\n",
            "  Batch 2,500  of  14,161.\n",
            "  Batch 2,550  of  14,161.\n",
            "  Batch 2,600  of  14,161.\n",
            "  Batch 2,650  of  14,161.\n",
            "  Batch 2,700  of  14,161.\n",
            "  Batch 2,750  of  14,161.\n",
            "  Batch 2,800  of  14,161.\n",
            "  Batch 2,850  of  14,161.\n",
            "  Batch 2,900  of  14,161.\n",
            "  Batch 2,950  of  14,161.\n",
            "  Batch 3,000  of  14,161.\n",
            "  Batch 3,050  of  14,161.\n",
            "  Batch 3,100  of  14,161.\n",
            "  Batch 3,150  of  14,161.\n",
            "  Batch 3,200  of  14,161.\n",
            "  Batch 3,250  of  14,161.\n",
            "  Batch 3,300  of  14,161.\n",
            "  Batch 3,350  of  14,161.\n",
            "  Batch 3,400  of  14,161.\n",
            "  Batch 3,450  of  14,161.\n",
            "  Batch 3,500  of  14,161.\n",
            "  Batch 3,550  of  14,161.\n",
            "  Batch 3,600  of  14,161.\n",
            "  Batch 3,650  of  14,161.\n",
            "  Batch 3,700  of  14,161.\n",
            "  Batch 3,750  of  14,161.\n",
            "  Batch 3,800  of  14,161.\n",
            "  Batch 3,850  of  14,161.\n",
            "  Batch 3,900  of  14,161.\n",
            "  Batch 3,950  of  14,161.\n",
            "  Batch 4,000  of  14,161.\n",
            "  Batch 4,050  of  14,161.\n",
            "  Batch 4,100  of  14,161.\n",
            "  Batch 4,150  of  14,161.\n",
            "  Batch 4,200  of  14,161.\n",
            "  Batch 4,250  of  14,161.\n",
            "  Batch 4,300  of  14,161.\n",
            "  Batch 4,350  of  14,161.\n",
            "  Batch 4,400  of  14,161.\n",
            "  Batch 4,450  of  14,161.\n",
            "  Batch 4,500  of  14,161.\n",
            "  Batch 4,550  of  14,161.\n",
            "  Batch 4,600  of  14,161.\n",
            "  Batch 4,650  of  14,161.\n",
            "  Batch 4,700  of  14,161.\n",
            "  Batch 4,750  of  14,161.\n",
            "  Batch 4,800  of  14,161.\n",
            "  Batch 4,850  of  14,161.\n",
            "  Batch 4,900  of  14,161.\n",
            "  Batch 4,950  of  14,161.\n",
            "  Batch 5,000  of  14,161.\n",
            "  Batch 5,050  of  14,161.\n",
            "  Batch 5,100  of  14,161.\n",
            "  Batch 5,150  of  14,161.\n",
            "  Batch 5,200  of  14,161.\n",
            "  Batch 5,250  of  14,161.\n",
            "  Batch 5,300  of  14,161.\n",
            "  Batch 5,350  of  14,161.\n",
            "  Batch 5,400  of  14,161.\n",
            "  Batch 5,450  of  14,161.\n",
            "  Batch 5,500  of  14,161.\n",
            "  Batch 5,550  of  14,161.\n",
            "  Batch 5,600  of  14,161.\n",
            "  Batch 5,650  of  14,161.\n",
            "  Batch 5,700  of  14,161.\n",
            "  Batch 5,750  of  14,161.\n",
            "  Batch 5,800  of  14,161.\n",
            "  Batch 5,850  of  14,161.\n",
            "  Batch 5,900  of  14,161.\n",
            "  Batch 5,950  of  14,161.\n",
            "  Batch 6,000  of  14,161.\n",
            "  Batch 6,050  of  14,161.\n",
            "  Batch 6,100  of  14,161.\n",
            "  Batch 6,150  of  14,161.\n",
            "  Batch 6,200  of  14,161.\n",
            "  Batch 6,250  of  14,161.\n",
            "  Batch 6,300  of  14,161.\n",
            "  Batch 6,350  of  14,161.\n",
            "  Batch 6,400  of  14,161.\n",
            "  Batch 6,450  of  14,161.\n",
            "  Batch 6,500  of  14,161.\n",
            "  Batch 6,550  of  14,161.\n",
            "  Batch 6,600  of  14,161.\n",
            "  Batch 6,650  of  14,161.\n",
            "  Batch 6,700  of  14,161.\n",
            "  Batch 6,750  of  14,161.\n",
            "  Batch 6,800  of  14,161.\n",
            "  Batch 6,850  of  14,161.\n",
            "  Batch 6,900  of  14,161.\n",
            "  Batch 6,950  of  14,161.\n",
            "  Batch 7,000  of  14,161.\n",
            "  Batch 7,050  of  14,161.\n",
            "  Batch 7,100  of  14,161.\n",
            "  Batch 7,150  of  14,161.\n",
            "  Batch 7,200  of  14,161.\n",
            "  Batch 7,250  of  14,161.\n",
            "  Batch 7,300  of  14,161.\n",
            "  Batch 7,350  of  14,161.\n",
            "  Batch 7,400  of  14,161.\n",
            "  Batch 7,450  of  14,161.\n",
            "  Batch 7,500  of  14,161.\n",
            "  Batch 7,550  of  14,161.\n",
            "  Batch 7,600  of  14,161.\n",
            "  Batch 7,650  of  14,161.\n",
            "  Batch 7,700  of  14,161.\n",
            "  Batch 7,750  of  14,161.\n",
            "  Batch 7,800  of  14,161.\n",
            "  Batch 7,850  of  14,161.\n",
            "  Batch 7,900  of  14,161.\n",
            "  Batch 7,950  of  14,161.\n",
            "  Batch 8,000  of  14,161.\n",
            "  Batch 8,050  of  14,161.\n",
            "  Batch 8,100  of  14,161.\n",
            "  Batch 8,150  of  14,161.\n",
            "  Batch 8,200  of  14,161.\n",
            "  Batch 8,250  of  14,161.\n",
            "  Batch 8,300  of  14,161.\n",
            "  Batch 8,350  of  14,161.\n",
            "  Batch 8,400  of  14,161.\n",
            "  Batch 8,450  of  14,161.\n",
            "  Batch 8,500  of  14,161.\n",
            "  Batch 8,550  of  14,161.\n",
            "  Batch 8,600  of  14,161.\n",
            "  Batch 8,650  of  14,161.\n",
            "  Batch 8,700  of  14,161.\n",
            "  Batch 8,750  of  14,161.\n",
            "  Batch 8,800  of  14,161.\n",
            "  Batch 8,850  of  14,161.\n",
            "  Batch 8,900  of  14,161.\n",
            "  Batch 8,950  of  14,161.\n",
            "  Batch 9,000  of  14,161.\n",
            "  Batch 9,050  of  14,161.\n",
            "  Batch 9,100  of  14,161.\n",
            "  Batch 9,150  of  14,161.\n",
            "  Batch 9,200  of  14,161.\n",
            "  Batch 9,250  of  14,161.\n",
            "  Batch 9,300  of  14,161.\n",
            "  Batch 9,350  of  14,161.\n",
            "  Batch 9,400  of  14,161.\n",
            "  Batch 9,450  of  14,161.\n",
            "  Batch 9,500  of  14,161.\n",
            "  Batch 9,550  of  14,161.\n",
            "  Batch 9,600  of  14,161.\n",
            "  Batch 9,650  of  14,161.\n",
            "  Batch 9,700  of  14,161.\n",
            "  Batch 9,750  of  14,161.\n",
            "  Batch 9,800  of  14,161.\n",
            "  Batch 9,850  of  14,161.\n",
            "  Batch 9,900  of  14,161.\n",
            "  Batch 9,950  of  14,161.\n",
            "  Batch 10,000  of  14,161.\n",
            "  Batch 10,050  of  14,161.\n",
            "  Batch 10,100  of  14,161.\n",
            "  Batch 10,150  of  14,161.\n",
            "  Batch 10,200  of  14,161.\n",
            "  Batch 10,250  of  14,161.\n",
            "  Batch 10,300  of  14,161.\n",
            "  Batch 10,350  of  14,161.\n",
            "  Batch 10,400  of  14,161.\n",
            "  Batch 10,450  of  14,161.\n",
            "  Batch 10,500  of  14,161.\n",
            "  Batch 10,550  of  14,161.\n",
            "  Batch 10,600  of  14,161.\n",
            "  Batch 10,650  of  14,161.\n",
            "  Batch 10,700  of  14,161.\n",
            "  Batch 10,750  of  14,161.\n",
            "  Batch 10,800  of  14,161.\n",
            "  Batch 10,850  of  14,161.\n",
            "  Batch 10,900  of  14,161.\n",
            "  Batch 10,950  of  14,161.\n",
            "  Batch 11,000  of  14,161.\n",
            "  Batch 11,050  of  14,161.\n",
            "  Batch 11,100  of  14,161.\n",
            "  Batch 11,150  of  14,161.\n",
            "  Batch 11,200  of  14,161.\n",
            "  Batch 11,250  of  14,161.\n",
            "  Batch 11,300  of  14,161.\n",
            "  Batch 11,350  of  14,161.\n",
            "  Batch 11,400  of  14,161.\n",
            "  Batch 11,450  of  14,161.\n",
            "  Batch 11,500  of  14,161.\n",
            "  Batch 11,550  of  14,161.\n",
            "  Batch 11,600  of  14,161.\n",
            "  Batch 11,650  of  14,161.\n",
            "  Batch 11,700  of  14,161.\n",
            "  Batch 11,750  of  14,161.\n",
            "  Batch 11,800  of  14,161.\n",
            "  Batch 11,850  of  14,161.\n",
            "  Batch 11,900  of  14,161.\n",
            "  Batch 11,950  of  14,161.\n",
            "  Batch 12,000  of  14,161.\n",
            "  Batch 12,050  of  14,161.\n",
            "  Batch 12,100  of  14,161.\n",
            "  Batch 12,150  of  14,161.\n",
            "  Batch 12,200  of  14,161.\n",
            "  Batch 12,250  of  14,161.\n",
            "  Batch 12,300  of  14,161.\n",
            "  Batch 12,350  of  14,161.\n",
            "  Batch 12,400  of  14,161.\n",
            "  Batch 12,450  of  14,161.\n",
            "  Batch 12,500  of  14,161.\n",
            "  Batch 12,550  of  14,161.\n",
            "  Batch 12,600  of  14,161.\n",
            "  Batch 12,650  of  14,161.\n",
            "  Batch 12,700  of  14,161.\n",
            "  Batch 12,750  of  14,161.\n",
            "  Batch 12,800  of  14,161.\n",
            "  Batch 12,850  of  14,161.\n",
            "  Batch 12,900  of  14,161.\n",
            "  Batch 12,950  of  14,161.\n",
            "  Batch 13,000  of  14,161.\n",
            "  Batch 13,050  of  14,161.\n",
            "  Batch 13,100  of  14,161.\n",
            "  Batch 13,150  of  14,161.\n",
            "  Batch 13,200  of  14,161.\n",
            "  Batch 13,250  of  14,161.\n",
            "  Batch 13,300  of  14,161.\n",
            "  Batch 13,350  of  14,161.\n",
            "  Batch 13,400  of  14,161.\n",
            "  Batch 13,450  of  14,161.\n",
            "  Batch 13,500  of  14,161.\n",
            "  Batch 13,550  of  14,161.\n",
            "  Batch 13,600  of  14,161.\n",
            "  Batch 13,650  of  14,161.\n",
            "  Batch 13,700  of  14,161.\n",
            "  Batch 13,750  of  14,161.\n",
            "  Batch 13,800  of  14,161.\n",
            "  Batch 13,850  of  14,161.\n",
            "  Batch 13,900  of  14,161.\n",
            "  Batch 13,950  of  14,161.\n",
            "  Batch 14,000  of  14,161.\n",
            "  Batch 14,050  of  14,161.\n",
            "  Batch 14,100  of  14,161.\n",
            "  Batch 14,150  of  14,161.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.637\n",
            "Validation Loss: 1.599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "W7ZvML6a0by4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3282f552-eaa8-4e9b-9846-9ec6c39e944a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "6sl37q5cfQJP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "H_vlb4cAPgvI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "id": "5NCzNWU1Pm5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb4bcd6-7c1f-422e-8e68-67e663468f66"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        18\n",
            "           1       0.00      0.00      0.00         9\n",
            "           2       0.00      0.00      0.00        10\n",
            "           3       0.00      0.00      0.00        13\n",
            "           4       0.00      0.00      0.00        23\n",
            "           5       0.00      0.00      0.00        55\n",
            "           6       0.00      0.00      0.00        48\n",
            "           7       0.00      0.00      0.00       166\n",
            "           8       0.00      0.00      0.00       452\n",
            "           9       0.00      0.00      0.00       781\n",
            "          10       0.78      1.00      0.87      5432\n",
            "\n",
            "    accuracy                           0.78      7007\n",
            "   macro avg       0.07      0.09      0.08      7007\n",
            "weighted avg       0.60      0.78      0.68      7007\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation for metrics:\n",
        "\n",
        "> **Accuracy**: Accuracy classification score. In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true. However, our data is unbalanced. Therefore, accuracy is not enough in this case.\n",
        "\n",
        "> **Precision**: Intuitively the ability of the classifier not to label as positive a sample that is negative. Precision is the estimated probability that a randomly selected retrieved document is relevant. For unbalanced data, precision helps understand how our model is successfull actually. \n",
        "\n",
        "> **Recall**: Intuitively the ability of the classifier to find all the positive samples. Recall is the estimated probability that a randomly selected relevant document is retrieved in a search. For this study, in addition to acuracy and precision, recall is another meaningful metric.\n",
        "\n",
        "> **F1 Score**: The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. F1 provides additional perspective to read precision and recall.\n"
      ],
      "metadata": {
        "id": "bYcZ7y_x2aWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interpretation**\n",
        "\n",
        "* Basically, all the SENTENCES are labeled as SCORE 10 with this model. This is a pretty bad prediction. (We don't even need an AI to label every SENTENCE as 10)\n",
        "\n",
        "* We can see why the model has such a bias to label SENTENCEs as SCORE 10. In total, 78% of the SENTENCEs has SCORE 10. \n",
        "* Weighted Average score is (68%). Weighted F1 score calculates the F1 score for each class independently but when it adds them together uses a weight that depends on the number of true labels of each class. This is overall performance of the model (highly weak)\n",
        "* Currently, I don't have a strong explanation for this undesirable performance result. But, in the scope of the take-home assignment, I will stop at this point. \n",
        "* If we desperately want to obtain a better model performance quickly, we can try Random Forest classifier, Multi-nominal Naive Bayes, and few other multi-label classification algorithms. However, they are all rule-based models. I would never suggest to use them in production. I strongly advice to spend time on building a better transformers-based language model."
      ],
      "metadata": {
        "id": "rZS0YQh2wFxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ideas for further improvement**\n",
        "\n",
        "* This prediction model can be trained with stronger/heavier Transformers models such as RoBERTa, T5-XL etc. We can expect performance improvement with different models.\n",
        "\n",
        "* I set ***batch_size = 8***. This can be done 32 or higher to run the training faster if there is a higher RAM\n",
        "* Training the model with more fine-tuned parameters have potential give to give better performance.\n",
        "\n",
        "* I wonder how the prediction performance would be if we use use Zero-Shot Classification approach. It worths giving it a try if we have enough time.\n",
        "\n",
        "* Of course with a larger training and validation datasets, and the model can be trained better, model performance can be improved.\n",
        "\n",
        "* As a data scientist, I can question the validity of the data, and try to understand potential biases in the dataset. Is there any threat to validity in the data gathering process? This point is part of a seperate discussion but still can affect the prediction performance.\n",
        "* All these suggestions needs to be evaluated regarding business needs, upcoming deadlines, stakeholders' priorities. "
      ],
      "metadata": {
        "id": "v5L9Z6RaiZCO"
      }
    }
  ]
}